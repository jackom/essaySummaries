在测试模型时，也务必要将数据集分解为训练数据和测试数据。如果不区分训练数据集和测试数据集，则在评估模型时会遇到问题，因为它已经看到了所有数据。我们需要的是独立的数据集，以确认模型可以很好地泛化，而不只是泛化到训练样本。

#####分类和回归
分类涉及到根据未见过的样本进行预测，并确定新实例属于哪个类别。例如，可以根据蓝色或红色或者方形或圆形来组织对象，以便在看到新对象时根据其特征来组织对象。

在回归中，我们想根据连续数据来进行预测。例如，我们有包含不同人员的身高、年龄和性别的列表，并想预测他们的体重。或者，像在本课程的最终项目中一样，我们可能有一些房屋数据，并想预测某所住宅的价值。

#####分类指标与回归指标
在分类中，我们想了解模型隔多久正确或不正确地识别新样本一次。而在回归中，我们可能更关注模型的预测值与真正值之间差多少。

在本节课的余下部分，我们会探讨几个性能指标。对于分类，我们会探讨准确率、精确率、召回率和 F 分数。对于回归，我们会探讨平均绝对误差和均方误差。

#####分类指标
对于分类，我们处理的是根据离散数据进行预测的模型。这就是说，此类模型确定新实例是否属于给定的一组类别。在这里，我们测量预测是否准确地将所讨论的实例进行分类。

准确率实际上是所有被正确标示的数据点除以所有的数据点。如果你是在看特定类的表现，我们需要看召回率（recall）

#####平均绝对误差
您可能已回想起，在统计学中可以使用绝对误差来测量误差，以找出预测值与真实值之间的差距。平均绝对误差的计算方法是，将各个样本的绝对误差汇总，然后根据数据点数量求出平均误差。通过将模型的所有绝对值加起来，可以避免因预测值比真实值过高或过低而抵销误差，并能获得用于评估模型的整体误差指标。

#####均方误差
均方误差是另一个经常用于测量模型性能的指标。与绝对误差相比，残差（预测值与真实值的差值）被求平方。

对残差求平方的一些好处是，自动将所有误差转换为正数、注重较大的误差而不是较小的误差以及在微积分中是可微的（可让我们找到最小值和最大值）。
有关均方误差和如何在 sklearn 中使用它的更多信息，请查看此链接[此处](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)。

#####回归分数函数
除了误差指标之外，scikit-learn还包括了两个分数指标，范围通常从0到1，值0为坏，而值1为最好的表现，看起来和分类指标类似，都是数字越接近1.0分数就越好。

- 其中之一是R2分数，用来计算真值预测的可决系数。在 scikit-learn 里，这也是回归学习器默认的分数方法。

- 另一个是可释方差分数

虽然眼下我们不会详细探讨这些指标，一个要记住的重点是，回归的默认指标是“分数越高越好”；即，越高的分数表明越好的表现。而当我们用到前面讲的误差指标时，我们要改变这个设定。

#####误差原因
我们已讨论了一些用于测量模型性能的基本指标，现在来关注一下模型起初为何会出现误差。

在模型预测中，模型可能出现的误差来自两个主要来源，即：因模型无法表示基本数据的复杂度而造成的偏差（bias），或者因模型对训练它所用的有限数据过度敏感而造成的方差（variance）。我们会对两者进行更详细的探讨。

#####偏差造成的误差 - 准确率和欠拟合
如前所述，如果模型具有足够的数据，但因不够复杂而无法捕捉基本关系，则会出现偏差。这样一来，模型一直会系统地错误表示数据，从而导致准确率降低。这种现象叫做欠拟合（underfitting）。

简单来说，如果模型不适当，就会出现偏差。举个例子：如果对象是按颜色和形状分类的，但模型只能按颜色来区分对象和将对象分类（模型过度简化），因而一直会错误地分类对象。

或者，我们可能有本质上是多项式的连续数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据并不重要，因为模型根本无法表示其中的基本关系，我们需要更复杂的模型。

#####方差造成的误差 - 精度和过拟合
在训练模型时，通常使用来自较大训练集的有限数量样本。如果利用随机选择的数据子集反复训练模型，可以预料它的预测结果会因提供给它的具体样本而异。在这里，方差（variance）用来测量预测结果对于任何给定的测试样本会出现多大的变化。

出现方差是正常的，但方差过高表明模型无法将其预测结果泛化到更多的数据。对训练集高度敏感也称为过拟合（overfitting），而且通常出现在模型过于复杂或我们没有足够的数据支持它时。

通常，可以利用更多数据进行训练，以降低模型预测结果的方差并提高精度。如果没有更多的数据可以用于训练，还可以通过限制模型的复杂度来降低方差。

#####改进模型的有效性
我们可以看到，在给定一组固定数据时，模型不能过于简单或复杂。如果过于简单，模型无法了解数据并会错误地表示数据。但是，如果建立非常复杂的模型，则需要更多数据才能了解基本关系，否则十分常见的是，模型会推断出在数据中实际上并不存在的关系。

关键在于，通过找出正确的模型复杂度来找到最大限度降低偏差和方差的最有效点。当然，数据越多，模型随着时间推移会变得越好。

#####学习曲线1
让我们根据模型通过可视化图形从数据中学习的能力来探讨偏差与方差之间的关系。

机器学习中的学习曲线是一种可视化图形，能根据一系列训练实例中的训练和测试数据比较模型的指标性能。

在查看数据与误差之间的关系时，我们通常会看到，随着训练点数量的增加，误差会趋于下降。由于我们尝试构建从经验中学习的模型，因此这很有意义。

我们将训练集和测试集分隔开，以便更好地了解能否将模型泛化到未见过的数据而不是拟合到刚见过的数据。

在学习曲线中，当训练曲线和测试曲线均达到稳定阶段，并且两者之间的差距不再变化时，则可以确认模型已尽其所能地了解数据。

#####学习曲线2
偏差
在训练误差和测试误差收敛并且相当高时，这实质上表示模型具有偏差。无论我们向其提供多少数据，模型都无法表示基本关系，因而出现系统性的高误差。

方差
如果训练误差与测试误差之间的差距很大，这实质上表示模型具有高方差。与偏差模型不同的是，如果有更多可供学习的数据，或者能简化表示数据的最重要特征的模型，则通常可以改进具有方差的模型。

#####理想的学习曲线
模型的最终目标是，误差小并能很好地泛化到未见过的数据（测试数据）。如果测试曲线和训练曲线均收敛，并且误差极低，就能看到这种模型。这种模型能根据未见过的数据非常准确地进行预测。

#####模型复杂度
与学习曲线图形不同，模型复杂度图形呈现的是模型复杂度如何改变训练曲线和测试曲线，而不是呈现用来训练模型的数据点数量。一般趋势是，随着模型增大，模型对固定的一组数据表现出更高的变化性。

#####学习曲线与模型复杂度
那么，学习曲线与模型复杂度之间有何关系？

如果我们获取具有同一组固定数据的相同机器学习算法的学习曲线，但为越来越高的模型复杂度创建几个图形，则所有学习曲线图形均代表模型复杂度图形。这就是说，如果我们获取了每个模型复杂度的最终测试误差和训练误差，并依据模型复杂度将它们可视化，则我们能够看到随着模型的增大模型的表现有多好。

